{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of FineTuned Model vs Base MarianMT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will compare translations using the English-Spanish Kaggle Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm as tqdm\n",
    "from evaluate import load\n",
    "from transformers import MarianMTModel, MarianTokenizer, MarianConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = pd.read_csv('../data/English-Spanish-Kaggle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing duplicate phrases from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = data_file.drop_duplicates(subset=['english'], keep='first', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[100000:len(df_clean) - 2800].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP_25/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "base_model_name = 'Helsinki-NLP/opus-mt-en-es'\n",
    "base_model = MarianMTModel.from_pretrained(base_model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(65001, 512, padding_idx=65000)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLU()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLU()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('fine_tuned_en_es.bin', map_location=torch.device('cpu'))\n",
    "config = MarianConfig.from_json_file('config.json')\n",
    "ft_model = MarianMTModel(config=config)\n",
    "ft_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, device, df, bertscore):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for row in tqdm.tqdm(range(len(df))):\n",
    "            \n",
    "            # Grab phrases from data frame\n",
    "            en_phrase = df['english'][row]\n",
    "            es_phrase = df['spanish'][row]\n",
    "            \n",
    "            # Grab tokenized version of phrases and generate translation\n",
    "            en_phrase = tokenizer([en_phrase], return_tensors='pt')\n",
    "            en_ids = model.generate(**en_phrase)\n",
    "            \n",
    "            # Grab tokenized versions of reference phrases\n",
    "            es_phrase = tokenizer([es_phrase], return_tensors='pt')\n",
    "            es_ids = model.generate(**es_phrase)\n",
    "            \n",
    "            # Return the untokenized reference and prediction\n",
    "            predictions = tokenizer.batch_decode(en_ids, skip_special_tokens=True)[0]\n",
    "            references = tokenizer.batch_decode(es_ids, skip_special_tokens=True)[0]\n",
    "            \n",
    "            all_predictions.append(predictions)\n",
    "            all_references.append(references)\n",
    "    \n",
    "    return bertscore.compute(predictions=all_predictions, references=all_references, device=device, lang='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:49<00:00,  2.11it/s]\n",
      "100%|██████████| 104/104 [00:49<00:00,  2.08it/s]\n"
     ]
    }
   ],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "ft_model_eval = eval_model(ft_model, torch.device('mps'), df_clean, bertscore=bertscore)\n",
    "base_model_eval = eval_model(base_model, torch.device('mps'), df_clean, bertscore=bertscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.815087792965082), np.float64(0.815087792965082))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ft_model_eval['f1']), np.mean(base_model_eval['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
