{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning MarianMT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP_25/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm as tqdm\n",
    "from evaluate import load\n",
    "from transformers import MarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will walk through fine tuning the pre-existing MarianMT english to spanish model using the OpenSubtitles english and spanish text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will parse the data and a sentence in a row, with each column representing the spanish version and english version. We will then split the data appropriately. We will export as a csv for later usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Importing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing English sentences\n",
    "with open('../data/en-es/OpenSubtitles.en-es.en') as en_text:\n",
    "    english_sent = [line.strip() for line in en_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/en-es/OpenSubtitles.en-es.es') as es_text:\n",
    "    spanish_sent = [line.strip() for line in es_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert they are the same size\n",
    "len(english_sent), len(spanish_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.DataFrame({\n",
    "    'english': english_sent,\n",
    "    'spanish': spanish_sent\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.to_csv('en-es_Full_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.read_csv('./1millsentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into 3 different sets. A test, validation, and test set. Each set will have english and spanish sentences. \n",
    "\n",
    "We will reserve 70% of our data for training, 10% for validation, and 20% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Training Data\n",
    "train_X = sentences['english'][:int(len(sentences) * .7)] # English only for input\n",
    "train_y = sentences['spanish'][:int(len(sentences) * .7)] # Spanish for target\n",
    "\n",
    "# Preparing Testing Data\n",
    "test_X = sentences['english'][int(len(sentences) * .7) : int(len(sentences) * .9)]\n",
    "test_y = sentences['spanish'][int(len(sentences) * .7) : int(len(sentences) * .9)]\n",
    "\n",
    "# Preparing Validation Data\n",
    "val_X = sentences['english'][int(len(sentences) * .9) : int(len(sentences))]\n",
    "val_y = sentences['spanish'][int(len(sentences) * .9) : int(len(sentences))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/brycekratzer/BoiseStateWork/SPRING25/NLP_Project_With_Branch/NLP-Final-Project-Translatinator/models/FineTuningMT.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brycekratzer/BoiseStateWork/SPRING25/NLP_Project_With_Branch/NLP-Final-Project-Translatinator/models/FineTuningMT.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Creating sample size to test code\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brycekratzer/BoiseStateWork/SPRING25/NLP_Project_With_Branch/NLP-Final-Project-Translatinator/models/FineTuningMT.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brycekratzer/BoiseStateWork/SPRING25/NLP_Project_With_Branch/NLP-Final-Project-Translatinator/models/FineTuningMT.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Preparing Training Data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brycekratzer/BoiseStateWork/SPRING25/NLP_Project_With_Branch/NLP-Final-Project-Translatinator/models/FineTuningMT.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_X \u001b[39m=\u001b[39m sentences_sample[\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(sentences_sample) \u001b[39m*\u001b[39m \u001b[39m.7\u001b[39m)] \u001b[39m# English only for input\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brycekratzer/BoiseStateWork/SPRING25/NLP_Project_With_Branch/NLP-Final-Project-Translatinator/models/FineTuningMT.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_y \u001b[39m=\u001b[39m sentences_sample[\u001b[39m'\u001b[39m\u001b[39mspanish\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(sentences_sample) \u001b[39m*\u001b[39m \u001b[39m.7\u001b[39m)] \u001b[39m# Spanish for target\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brycekratzer/BoiseStateWork/SPRING25/NLP_Project_With_Branch/NLP-Final-Project-Translatinator/models/FineTuningMT.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Preparing Testing Data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences_sample' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating sample size to test code\n",
    "\n",
    "# Preparing Training Data\n",
    "train_X = sentences_sample['english'][:int(len(sentences_sample) * .7)] # English only for input\n",
    "train_y = sentences_sample['spanish'][:int(len(sentences_sample) * .7)] # Spanish for target\n",
    "\n",
    "# Preparing Testing Data\n",
    "test_X = sentences_sample['english'][int(len(sentences_sample) * .7) : int(len(sentences_sample) * .9)]\n",
    "test_y = sentences_sample['spanish'][int(len(sentences_sample) * .7) : int(len(sentences_sample) * .9)]\n",
    "\n",
    "# Preparing Validation Data\n",
    "val_X = sentences_sample['english'][int(len(sentences_sample) * .9) : int(len(sentences_sample))]\n",
    "val_y = sentences_sample['spanish'][int(len(sentences_sample) * .9) : int(len(sentences_sample))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are converting our data into a datatype that is acceptable for the DataLoader class. The DataLoader class loads a certain amount of data to input to the model based on the batch size during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to tokenize our inputs so we can represent our text as a numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP_25/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Helsinki-NLP/opus-mt-en-es'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting our data into a torch tensor\n",
    "train_X = np.array(train_X)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "test_X = np.array(test_X)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "val_X = np.array(val_X)\n",
    "val_y = np.array(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        \n",
    "        # Creating a dataset of inputs to model, and their outputs\n",
    "        for data_X, data_y in zip(X, y):\n",
    "            \n",
    "            # Handles if the input file has Non-string like objects\n",
    "            if isinstance(data_X, str) and isinstance(data_y, str):\n",
    "                \n",
    "                # Tokenize text\n",
    "                inputs = tokenizer(data_X, max_length=128, padding='max_length', truncation=True)\n",
    "                with tokenizer.as_target_tokenizer():\n",
    "                    targets = tokenizer(data_y, max_length=128, padding='max_length', truncation=True)\n",
    "                \n",
    "                # Add tokenized text to our data sets\n",
    "                self.input_ids.append(inputs['input_ids'])\n",
    "                self.target_ids.append(targets['input_ids'])\n",
    "        \n",
    "        # Convert to tensors\n",
    "        self.input_ids = torch.tensor(self.input_ids)\n",
    "        self.target_ids = torch.tensor(self.target_ids)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'input': self.input_ids[index],\n",
    "            'target': self.target_ids[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP_25/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TextDataset(train_X, train_y, tokenizer)\n",
    "test_dataset = TextDataset(test_X, test_y, tokenizer)\n",
    "val_dataset = TextDataset(val_X, val_y, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset based on our sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Create DataLoaders \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be fine-tuning the MarianMT with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Helsinki-NLP/opus-mt-en-es'\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "base_model = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "model.to(device)    \n",
    "base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in tqdm.tqdm(training_loader):\n",
    "        ids = data['input'].to(device, dtype = torch.long)\n",
    "        targets = data['target'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, labels=targets)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        \n",
    "    return total_loss / len(training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, tokenizer, bertscore):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm.tqdm(test_loader):\n",
    "            targets = data['target'].to(device, dtype = torch.long)\n",
    "            ids = data['input'].to(device, dtype = torch.long)\n",
    "            generated_ids = model.generate(input_ids = ids)\n",
    "            \n",
    "            predictions = tokenizer.batch_decode(generated_ids, kip_special_tokens=True)[0]\n",
    "            references = tokenizer.batch_decode(targets, skip_special_tokens=True)[0]\n",
    "            \n",
    "            all_predictions.append(predictions)\n",
    "            all_references.append(references)\n",
    "        results = bertscore.compute(predictions=all_predictions, references=all_references, lang='es', device=device)\n",
    "    return results['f1'], all_predictions, all_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=.0001)\n",
    "NUM_EPOCH = 3\n",
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    loss = train(model, train_loader, optim)\n",
    "    \n",
    "    f1_score = val(model, val_loader, tokenizer, bertscore)\n",
    "    print(f'Epoch: {epoch+1} \\nBERTScore F1: {f1_score}\\nTraining Loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to computational resources we will have to evalutate on a smaller dataset. See the Evaluate.ipynb for testing both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_based_model = test(base_model, test_loader, tokenizer, bertscore)\n",
    "f1_score_finetuned = test(model, test_loader, tokenizer, bertscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(f1_score_based_model), np.mean(f1_score_finetuned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
